{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d812a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib, os, random\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3eb76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input,Flatten, Dropout,GlobalMaxPooling2D,Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b671d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'train', 'val']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('FishImgDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c027555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 'FishImgDataset/train'\n",
    "validation = 'FishImgDataset/val'\n",
    "test = 'FishImgDataset/test' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a68580",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                   shear_range = 0.2,  \n",
    "                                   zoom_range = 0.2,  \n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e378b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale = 1.0/255.) \n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b509e0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8791 images belonging to 31 classes.\n",
      "Found 2751 images belonging to 31 classes.\n",
      "Found 1760 images belonging to 31 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(train, target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "validation_generator = valid_datagen.flow_from_directory(validation, target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test, target_size=(224,224),batch_size=32,class_mode='categorical',shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1313a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 29s 0us/step\n"
     ]
    }
   ],
   "source": [
    "inception = tf.keras.applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b89698eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception.trainable = True\n",
    "for layer in inception.layers[:197]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed1c4e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0:  input_1: trainable = False\n",
      " 1:  conv2d: trainable = False\n",
      " 2:  batch_normalization: trainable = False\n",
      " 3:  activation: trainable = False\n",
      " 4:  conv2d_1: trainable = False\n",
      " 5:  batch_normalization_1: trainable = False\n",
      " 6:  activation_1: trainable = False\n",
      " 7:  conv2d_2: trainable = False\n",
      " 8:  batch_normalization_2: trainable = False\n",
      " 9:  activation_2: trainable = False\n",
      " 10:  max_pooling2d: trainable = False\n",
      " 11:  conv2d_3: trainable = False\n",
      " 12:  batch_normalization_3: trainable = False\n",
      " 13:  activation_3: trainable = False\n",
      " 14:  conv2d_4: trainable = False\n",
      " 15:  batch_normalization_4: trainable = False\n",
      " 16:  activation_4: trainable = False\n",
      " 17:  max_pooling2d_1: trainable = False\n",
      " 18:  conv2d_8: trainable = False\n",
      " 19:  batch_normalization_8: trainable = False\n",
      " 20:  activation_8: trainable = False\n",
      " 21:  conv2d_6: trainable = False\n",
      " 22:  conv2d_9: trainable = False\n",
      " 23:  batch_normalization_6: trainable = False\n",
      " 24:  batch_normalization_9: trainable = False\n",
      " 25:  activation_6: trainable = False\n",
      " 26:  activation_9: trainable = False\n",
      " 27:  average_pooling2d: trainable = False\n",
      " 28:  conv2d_5: trainable = False\n",
      " 29:  conv2d_7: trainable = False\n",
      " 30:  conv2d_10: trainable = False\n",
      " 31:  conv2d_11: trainable = False\n",
      " 32:  batch_normalization_5: trainable = False\n",
      " 33:  batch_normalization_7: trainable = False\n",
      " 34:  batch_normalization_10: trainable = False\n",
      " 35:  batch_normalization_11: trainable = False\n",
      " 36:  activation_5: trainable = False\n",
      " 37:  activation_7: trainable = False\n",
      " 38:  activation_10: trainable = False\n",
      " 39:  activation_11: trainable = False\n",
      " 40:  mixed0: trainable = False\n",
      " 41:  conv2d_15: trainable = False\n",
      " 42:  batch_normalization_15: trainable = False\n",
      " 43:  activation_15: trainable = False\n",
      " 44:  conv2d_13: trainable = False\n",
      " 45:  conv2d_16: trainable = False\n",
      " 46:  batch_normalization_13: trainable = False\n",
      " 47:  batch_normalization_16: trainable = False\n",
      " 48:  activation_13: trainable = False\n",
      " 49:  activation_16: trainable = False\n",
      " 50:  average_pooling2d_1: trainable = False\n",
      " 51:  conv2d_12: trainable = False\n",
      " 52:  conv2d_14: trainable = False\n",
      " 53:  conv2d_17: trainable = False\n",
      " 54:  conv2d_18: trainable = False\n",
      " 55:  batch_normalization_12: trainable = False\n",
      " 56:  batch_normalization_14: trainable = False\n",
      " 57:  batch_normalization_17: trainable = False\n",
      " 58:  batch_normalization_18: trainable = False\n",
      " 59:  activation_12: trainable = False\n",
      " 60:  activation_14: trainable = False\n",
      " 61:  activation_17: trainable = False\n",
      " 62:  activation_18: trainable = False\n",
      " 63:  mixed1: trainable = False\n",
      " 64:  conv2d_22: trainable = False\n",
      " 65:  batch_normalization_22: trainable = False\n",
      " 66:  activation_22: trainable = False\n",
      " 67:  conv2d_20: trainable = False\n",
      " 68:  conv2d_23: trainable = False\n",
      " 69:  batch_normalization_20: trainable = False\n",
      " 70:  batch_normalization_23: trainable = False\n",
      " 71:  activation_20: trainable = False\n",
      " 72:  activation_23: trainable = False\n",
      " 73:  average_pooling2d_2: trainable = False\n",
      " 74:  conv2d_19: trainable = False\n",
      " 75:  conv2d_21: trainable = False\n",
      " 76:  conv2d_24: trainable = False\n",
      " 77:  conv2d_25: trainable = False\n",
      " 78:  batch_normalization_19: trainable = False\n",
      " 79:  batch_normalization_21: trainable = False\n",
      " 80:  batch_normalization_24: trainable = False\n",
      " 81:  batch_normalization_25: trainable = False\n",
      " 82:  activation_19: trainable = False\n",
      " 83:  activation_21: trainable = False\n",
      " 84:  activation_24: trainable = False\n",
      " 85:  activation_25: trainable = False\n",
      " 86:  mixed2: trainable = False\n",
      " 87:  conv2d_27: trainable = False\n",
      " 88:  batch_normalization_27: trainable = False\n",
      " 89:  activation_27: trainable = False\n",
      " 90:  conv2d_28: trainable = False\n",
      " 91:  batch_normalization_28: trainable = False\n",
      " 92:  activation_28: trainable = False\n",
      " 93:  conv2d_26: trainable = False\n",
      " 94:  conv2d_29: trainable = False\n",
      " 95:  batch_normalization_26: trainable = False\n",
      " 96:  batch_normalization_29: trainable = False\n",
      " 97:  activation_26: trainable = False\n",
      " 98:  activation_29: trainable = False\n",
      " 99:  max_pooling2d_2: trainable = False\n",
      " 100:  mixed3: trainable = False\n",
      " 101:  conv2d_34: trainable = False\n",
      " 102:  batch_normalization_34: trainable = False\n",
      " 103:  activation_34: trainable = False\n",
      " 104:  conv2d_35: trainable = False\n",
      " 105:  batch_normalization_35: trainable = False\n",
      " 106:  activation_35: trainable = False\n",
      " 107:  conv2d_31: trainable = False\n",
      " 108:  conv2d_36: trainable = False\n",
      " 109:  batch_normalization_31: trainable = False\n",
      " 110:  batch_normalization_36: trainable = False\n",
      " 111:  activation_31: trainable = False\n",
      " 112:  activation_36: trainable = False\n",
      " 113:  conv2d_32: trainable = False\n",
      " 114:  conv2d_37: trainable = False\n",
      " 115:  batch_normalization_32: trainable = False\n",
      " 116:  batch_normalization_37: trainable = False\n",
      " 117:  activation_32: trainable = False\n",
      " 118:  activation_37: trainable = False\n",
      " 119:  average_pooling2d_3: trainable = False\n",
      " 120:  conv2d_30: trainable = False\n",
      " 121:  conv2d_33: trainable = False\n",
      " 122:  conv2d_38: trainable = False\n",
      " 123:  conv2d_39: trainable = False\n",
      " 124:  batch_normalization_30: trainable = False\n",
      " 125:  batch_normalization_33: trainable = False\n",
      " 126:  batch_normalization_38: trainable = False\n",
      " 127:  batch_normalization_39: trainable = False\n",
      " 128:  activation_30: trainable = False\n",
      " 129:  activation_33: trainable = False\n",
      " 130:  activation_38: trainable = False\n",
      " 131:  activation_39: trainable = False\n",
      " 132:  mixed4: trainable = False\n",
      " 133:  conv2d_44: trainable = False\n",
      " 134:  batch_normalization_44: trainable = False\n",
      " 135:  activation_44: trainable = False\n",
      " 136:  conv2d_45: trainable = False\n",
      " 137:  batch_normalization_45: trainable = False\n",
      " 138:  activation_45: trainable = False\n",
      " 139:  conv2d_41: trainable = False\n",
      " 140:  conv2d_46: trainable = False\n",
      " 141:  batch_normalization_41: trainable = False\n",
      " 142:  batch_normalization_46: trainable = False\n",
      " 143:  activation_41: trainable = False\n",
      " 144:  activation_46: trainable = False\n",
      " 145:  conv2d_42: trainable = False\n",
      " 146:  conv2d_47: trainable = False\n",
      " 147:  batch_normalization_42: trainable = False\n",
      " 148:  batch_normalization_47: trainable = False\n",
      " 149:  activation_42: trainable = False\n",
      " 150:  activation_47: trainable = False\n",
      " 151:  average_pooling2d_4: trainable = False\n",
      " 152:  conv2d_40: trainable = False\n",
      " 153:  conv2d_43: trainable = False\n",
      " 154:  conv2d_48: trainable = False\n",
      " 155:  conv2d_49: trainable = False\n",
      " 156:  batch_normalization_40: trainable = False\n",
      " 157:  batch_normalization_43: trainable = False\n",
      " 158:  batch_normalization_48: trainable = False\n",
      " 159:  batch_normalization_49: trainable = False\n",
      " 160:  activation_40: trainable = False\n",
      " 161:  activation_43: trainable = False\n",
      " 162:  activation_48: trainable = False\n",
      " 163:  activation_49: trainable = False\n",
      " 164:  mixed5: trainable = False\n",
      " 165:  conv2d_54: trainable = False\n",
      " 166:  batch_normalization_54: trainable = False\n",
      " 167:  activation_54: trainable = False\n",
      " 168:  conv2d_55: trainable = False\n",
      " 169:  batch_normalization_55: trainable = False\n",
      " 170:  activation_55: trainable = False\n",
      " 171:  conv2d_51: trainable = False\n",
      " 172:  conv2d_56: trainable = False\n",
      " 173:  batch_normalization_51: trainable = False\n",
      " 174:  batch_normalization_56: trainable = False\n",
      " 175:  activation_51: trainable = False\n",
      " 176:  activation_56: trainable = False\n",
      " 177:  conv2d_52: trainable = False\n",
      " 178:  conv2d_57: trainable = False\n",
      " 179:  batch_normalization_52: trainable = False\n",
      " 180:  batch_normalization_57: trainable = False\n",
      " 181:  activation_52: trainable = False\n",
      " 182:  activation_57: trainable = False\n",
      " 183:  average_pooling2d_5: trainable = False\n",
      " 184:  conv2d_50: trainable = False\n",
      " 185:  conv2d_53: trainable = False\n",
      " 186:  conv2d_58: trainable = False\n",
      " 187:  conv2d_59: trainable = False\n",
      " 188:  batch_normalization_50: trainable = False\n",
      " 189:  batch_normalization_53: trainable = False\n",
      " 190:  batch_normalization_58: trainable = False\n",
      " 191:  batch_normalization_59: trainable = False\n",
      " 192:  activation_50: trainable = False\n",
      " 193:  activation_53: trainable = False\n",
      " 194:  activation_58: trainable = False\n",
      " 195:  activation_59: trainable = False\n",
      " 196:  mixed6: trainable = False\n",
      " 197:  conv2d_64: trainable = True\n",
      " 198:  batch_normalization_64: trainable = True\n",
      " 199:  activation_64: trainable = True\n",
      " 200:  conv2d_65: trainable = True\n",
      " 201:  batch_normalization_65: trainable = True\n",
      " 202:  activation_65: trainable = True\n",
      " 203:  conv2d_61: trainable = True\n",
      " 204:  conv2d_66: trainable = True\n",
      " 205:  batch_normalization_61: trainable = True\n",
      " 206:  batch_normalization_66: trainable = True\n",
      " 207:  activation_61: trainable = True\n",
      " 208:  activation_66: trainable = True\n",
      " 209:  conv2d_62: trainable = True\n",
      " 210:  conv2d_67: trainable = True\n",
      " 211:  batch_normalization_62: trainable = True\n",
      " 212:  batch_normalization_67: trainable = True\n",
      " 213:  activation_62: trainable = True\n",
      " 214:  activation_67: trainable = True\n",
      " 215:  average_pooling2d_6: trainable = True\n",
      " 216:  conv2d_60: trainable = True\n",
      " 217:  conv2d_63: trainable = True\n",
      " 218:  conv2d_68: trainable = True\n",
      " 219:  conv2d_69: trainable = True\n",
      " 220:  batch_normalization_60: trainable = True\n",
      " 221:  batch_normalization_63: trainable = True\n",
      " 222:  batch_normalization_68: trainable = True\n",
      " 223:  batch_normalization_69: trainable = True\n",
      " 224:  activation_60: trainable = True\n",
      " 225:  activation_63: trainable = True\n",
      " 226:  activation_68: trainable = True\n",
      " 227:  activation_69: trainable = True\n",
      " 228:  mixed7: trainable = True\n",
      " 229:  conv2d_72: trainable = True\n",
      " 230:  batch_normalization_72: trainable = True\n",
      " 231:  activation_72: trainable = True\n",
      " 232:  conv2d_73: trainable = True\n",
      " 233:  batch_normalization_73: trainable = True\n",
      " 234:  activation_73: trainable = True\n",
      " 235:  conv2d_70: trainable = True\n",
      " 236:  conv2d_74: trainable = True\n",
      " 237:  batch_normalization_70: trainable = True\n",
      " 238:  batch_normalization_74: trainable = True\n",
      " 239:  activation_70: trainable = True\n",
      " 240:  activation_74: trainable = True\n",
      " 241:  conv2d_71: trainable = True\n",
      " 242:  conv2d_75: trainable = True\n",
      " 243:  batch_normalization_71: trainable = True\n",
      " 244:  batch_normalization_75: trainable = True\n",
      " 245:  activation_71: trainable = True\n",
      " 246:  activation_75: trainable = True\n",
      " 247:  max_pooling2d_3: trainable = True\n",
      " 248:  mixed8: trainable = True\n",
      " 249:  conv2d_80: trainable = True\n",
      " 250:  batch_normalization_80: trainable = True\n",
      " 251:  activation_80: trainable = True\n",
      " 252:  conv2d_77: trainable = True\n",
      " 253:  conv2d_81: trainable = True\n",
      " 254:  batch_normalization_77: trainable = True\n",
      " 255:  batch_normalization_81: trainable = True\n",
      " 256:  activation_77: trainable = True\n",
      " 257:  activation_81: trainable = True\n",
      " 258:  conv2d_78: trainable = True\n",
      " 259:  conv2d_79: trainable = True\n",
      " 260:  conv2d_82: trainable = True\n",
      " 261:  conv2d_83: trainable = True\n",
      " 262:  average_pooling2d_7: trainable = True\n",
      " 263:  conv2d_76: trainable = True\n",
      " 264:  batch_normalization_78: trainable = True\n",
      " 265:  batch_normalization_79: trainable = True\n",
      " 266:  batch_normalization_82: trainable = True\n",
      " 267:  batch_normalization_83: trainable = True\n",
      " 268:  conv2d_84: trainable = True\n",
      " 269:  batch_normalization_76: trainable = True\n",
      " 270:  activation_78: trainable = True\n",
      " 271:  activation_79: trainable = True\n",
      " 272:  activation_82: trainable = True\n",
      " 273:  activation_83: trainable = True\n",
      " 274:  batch_normalization_84: trainable = True\n",
      " 275:  activation_76: trainable = True\n",
      " 276:  mixed9_0: trainable = True\n",
      " 277:  concatenate: trainable = True\n",
      " 278:  activation_84: trainable = True\n",
      " 279:  mixed9: trainable = True\n",
      " 280:  conv2d_89: trainable = True\n",
      " 281:  batch_normalization_89: trainable = True\n",
      " 282:  activation_89: trainable = True\n",
      " 283:  conv2d_86: trainable = True\n",
      " 284:  conv2d_90: trainable = True\n",
      " 285:  batch_normalization_86: trainable = True\n",
      " 286:  batch_normalization_90: trainable = True\n",
      " 287:  activation_86: trainable = True\n",
      " 288:  activation_90: trainable = True\n",
      " 289:  conv2d_87: trainable = True\n",
      " 290:  conv2d_88: trainable = True\n",
      " 291:  conv2d_91: trainable = True\n",
      " 292:  conv2d_92: trainable = True\n",
      " 293:  average_pooling2d_8: trainable = True\n",
      " 294:  conv2d_85: trainable = True\n",
      " 295:  batch_normalization_87: trainable = True\n",
      " 296:  batch_normalization_88: trainable = True\n",
      " 297:  batch_normalization_91: trainable = True\n",
      " 298:  batch_normalization_92: trainable = True\n",
      " 299:  conv2d_93: trainable = True\n",
      " 300:  batch_normalization_85: trainable = True\n",
      " 301:  activation_87: trainable = True\n",
      " 302:  activation_88: trainable = True\n",
      " 303:  activation_91: trainable = True\n",
      " 304:  activation_92: trainable = True\n",
      " 305:  batch_normalization_93: trainable = True\n",
      " 306:  activation_85: trainable = True\n",
      " 307:  mixed9_1: trainable = True\n",
      " 308:  concatenate_1: trainable = True\n",
      " 309:  activation_93: trainable = True\n",
      " 310:  mixed10: trainable = True\n"
     ]
    }
   ],
   "source": [
    "for idx, layer in enumerate(inception.layers):\n",
    "    print(f' {idx}:  {layer.name}: trainable = {layer.trainable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "137e7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = inception.get_layer('mixed7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8a75fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "470eaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = len(os.listdir('FishImgDataset/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "668dfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = Flatten()(layer_output)\n",
    "xs = Dense(1024,activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001))(xs)\n",
    "xs = Dropout(0.4)(xs)\n",
    "xs = Dense(n_categories, activation='softmax')(xs)\n",
    "\n",
    "model = Model(inputs=inception.inputs, outputs=xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3daae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb9c2532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da02e30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "275/275 [==============================] - 1341s 5s/step - loss: 2.1639 - accuracy: 0.6756 - val_loss: 1.0030 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "275/275 [==============================] - 1277s 5s/step - loss: 1.0066 - accuracy: 0.8914 - val_loss: 0.6806 - val_accuracy: 0.9673 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "275/275 [==============================] - 1282s 5s/step - loss: 0.7053 - accuracy: 0.9346 - val_loss: 0.5130 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "275/275 [==============================] - 1284s 5s/step - loss: 0.5351 - accuracy: 0.9501 - val_loss: 0.4101 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "275/275 [==============================] - 1275s 5s/step - loss: 0.4195 - accuracy: 0.9619 - val_loss: 0.3155 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "275/275 [==============================] - 1268s 5s/step - loss: 0.3362 - accuracy: 0.9669 - val_loss: 0.2751 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "275/275 [==============================] - 1286s 5s/step - loss: 0.2793 - accuracy: 0.9722 - val_loss: 0.2377 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "275/275 [==============================] - 1327s 5s/step - loss: 0.2467 - accuracy: 0.9772 - val_loss: 0.2051 - val_accuracy: 0.9905 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "275/275 [==============================] - 1292s 5s/step - loss: 0.2071 - accuracy: 0.9772 - val_loss: 0.1958 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "275/275 [==============================] - 1280s 5s/step - loss: 0.1850 - accuracy: 0.9803 - val_loss: 0.1708 - val_accuracy: 0.9873 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            epochs = 10, #10\n",
    "            callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5b3b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'FishModelClassifier_V6.h5'\n",
    "model.save(model_name, save_format='h5')\n",
    "model.save_weights('model_weights_V6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e35fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=['Bangus', 'Big Head Carp', 'Black Spotted Barb', 'Catfish', 'Climbing Perch', 'Fourfinger Threadfin',\n",
    "        'Freshwater Eel', 'Glass Perchlet', 'Goby', 'Gold Fish', 'Gourami', 'Grass Carp', 'Green Spotted Puffer',\n",
    "        'Indian Carp', 'Indo-Pacific Tarpon', 'Jaguar Gapote', 'Janitor Fish', 'Knifefish', 'Long-Snouted Pipefish',\n",
    "        'Mosquito Fish', 'Mudfish', 'Mullet', 'Pangasius', 'Perch', 'Scat Fish', 'Silver Barb', 'Silver Carp',\n",
    "        'Silver Perch', 'Snakehead', 'Tenpounder', 'Tilapia']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1f246ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "324b2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(path):\n",
    "    img=load_img(path,target_size=(224,224,3))#convert image size and declare the kernel\n",
    "    img=img_to_array(img)#convert the image to an image array\n",
    "    img=img/255 #rgb is 255\n",
    "    img=np.expand_dims(img,[0])\n",
    "    answer=model.predict(img)\n",
    "    x = list(np.argsort(answer[0])[::-1][:5])\n",
    "    \n",
    "    for i in x:\n",
    "        print(\"{className}: {predVal:.2f}%\".format(className=class_name[i], predVal=float(answer[0][i])*100))\n",
    "    \n",
    "    y_class=answer.argmax(axis=-1)\n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = class_name[y]\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ffcfa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 284ms/step\n",
      "Catfish: 100.00%\n",
      "Grass Carp: 0.00%\n",
      "Freshwater Eel: 0.00%\n",
      "Big Head Carp: 0.00%\n",
      "Knifefish: 0.00%\n",
      "Catfish\n"
     ]
    }
   ],
   "source": [
    "img='C:\\\\Users\\\\hp\\\\FishImgDataset\\\\train\\\\Catfish\\\\0b17caaa-b3a0-4302-a59b-4b02da660189-1200mm.jpg'\n",
    "img2='C:\\\\Users\\\\hp\\Downloads\\\\catfish.jpeg'\n",
    "print(predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be46314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
